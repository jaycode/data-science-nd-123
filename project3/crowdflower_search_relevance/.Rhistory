TT.options=list(path=treetagger_path, preset="en")))
# When everything is correct, following code should display the lemma for given words:
tagged_results <- tagged.results@TT.res
return(PlainTextDocument(paste(unlist(tagged_results$lemma),collapse=' ')))
}
lemmatize_corpus <- function(corpus) {
corpus <- tm_map(corpus, lemmatizeDocument)
# tagged.results <- treetag(corpus$content, treetagger="manual", format="obj",
#                       TT.tknz=FALSE , lang=language,
#                       TT.options=list(path=treetagger_path, preset="en"))
tagged_results <- tagged.results@TT.res
corpus_text <- data.frame(
text=unlist(sapply(corpus, `[`, "content")),
stringsAsFactors=F
)
# "Simple" word count with regex.
corpus_text$count <- sapply(gregexpr("\\b\\W+\\b", corpus_text$text, perl=TRUE), function(x) sum(x>0) ) + 1
return(corpus_text)
}
test_lemmatize_corpus <- function() {
df <- data.frame(query = c('run',
'running',
'runs running',
'running shoes',
'ran',
'I am running'))
df$query <- as.character(df$query)
corpus <- prepare_corpus(df, 'query')
# corpus_text <- lemmatizeDocument(df$query)
corpus_text <- lemmatize_corpus(corpus)
browser()
stopifnot(
all.equal(corpus_text$text[1], 'run'),
all.equal(corpus_text$count[1], 1),
all.equal(corpus_text$text[2], 'run'),
all.equal(corpus_text$count[2], 1),
all.equal(corpus_text$text[3], 'run run'),
all.equal(corpus_text$count[3], 2),
all.equal(corpus_text$text[4], 'run shoe'),
all.equal(corpus_text$count[4], 2),
all.equal(corpus_text$text[5], 'run'),
all.equal(corpus_text$count[5], 1),
all.equal(corpus_text$text[6], 'I be run'),
all.equal(corpus_text$count[6], 3)
)
}
test_lemmatize_corpus()
corpus_text$text[3]
corpus_text$text[6]
corpus_text$text[5]
corpus_text$text[6]
counter <- 0
# This is an equivalent of function "stemDocument" when we did our stemming algorithm earlier.
lemmatizeDocument <- function(x, language = 'en') {
suppressMessages(tagged.results <- treetag(content(x), treetagger="manual", format="obj",
TT.tknz=FALSE , lang=language,
TT.options=list(path=treetagger_path, preset="en")))
# When everything is correct, following code should display the lemma for given words:
tagged_results <- tagged.results@TT.res
counter <- counter + 1
cat("count: ", counter)
return(PlainTextDocument(paste(unlist(tagged_results$lemma),collapse=' ')))
}
lemmatize_corpus <- function(corpus) {
corpus <- tm_map(corpus, lemmatizeDocument)
# tagged.results <- treetag(corpus$content, treetagger="manual", format="obj",
#                       TT.tknz=FALSE , lang=language,
#                       TT.options=list(path=treetagger_path, preset="en"))
tagged_results <- tagged.results@TT.res
corpus_text <- data.frame(
text=unlist(sapply(corpus, `[`, "content")),
stringsAsFactors=F
)
# "Simple" word count with regex.
corpus_text$count <- sapply(gregexpr("\\b\\W+\\b", corpus_text$text, perl=TRUE), function(x) sum(x>0) ) + 1
return(corpus_text)
}
test_lemmatize_corpus <- function() {
df <- data.frame(query = c('run',
'running',
'runs running',
'running shoes',
'ran',
'I am running'))
df$query <- as.character(df$query)
corpus <- prepare_corpus(df, 'query')
# corpus_text <- lemmatizeDocument(df$query)
corpus_text <- lemmatize_corpus(corpus)
browser()
stopifnot(
all.equal(corpus_text$text[1], 'run'),
all.equal(corpus_text$count[1], 1),
all.equal(corpus_text$text[2], 'run'),
all.equal(corpus_text$count[2], 1),
all.equal(corpus_text$text[3], 'run run'),
all.equal(corpus_text$count[3], 2),
all.equal(corpus_text$text[4], 'run shoe'),
all.equal(corpus_text$count[4], 2),
all.equal(corpus_text$text[5], 'run'),
all.equal(corpus_text$count[5], 1),
all.equal(corpus_text$text[6], 'run'),
all.equal(corpus_text$count[6], 1)
)
}
test_lemmatize_corpus()
counter <<- 0
# This is an equivalent of function "stemDocument" when we did our stemming algorithm earlier.
lemmatizeDocument <- function(x, language = 'en') {
suppressMessages(tagged.results <- treetag(content(x), treetagger="manual", format="obj",
TT.tknz=FALSE , lang=language,
TT.options=list(path=treetagger_path, preset="en")))
# When everything is correct, following code should display the lemma for given words:
tagged_results <- tagged.results@TT.res
counter <<- counter + 1
cat("count: ", counter)
return(PlainTextDocument(paste(unlist(tagged_results$lemma),collapse=' ')))
}
lemmatize_corpus <- function(corpus) {
corpus <- tm_map(corpus, lemmatizeDocument)
# tagged.results <- treetag(corpus$content, treetagger="manual", format="obj",
#                       TT.tknz=FALSE , lang=language,
#                       TT.options=list(path=treetagger_path, preset="en"))
tagged_results <- tagged.results@TT.res
corpus_text <- data.frame(
text=unlist(sapply(corpus, `[`, "content")),
stringsAsFactors=F
)
# "Simple" word count with regex.
corpus_text$count <- sapply(gregexpr("\\b\\W+\\b", corpus_text$text, perl=TRUE), function(x) sum(x>0) ) + 1
return(corpus_text)
}
test_lemmatize_corpus <- function() {
df <- data.frame(query = c('run',
'running',
'runs running',
'running shoes',
'ran',
'I am running'))
df$query <- as.character(df$query)
corpus <- prepare_corpus(df, 'query')
# corpus_text <- lemmatizeDocument(df$query)
corpus_text <- lemmatize_corpus(corpus)
stopifnot(
all.equal(corpus_text$text[1], 'run'),
all.equal(corpus_text$count[1], 1),
all.equal(corpus_text$text[2], 'run'),
all.equal(corpus_text$count[2], 1),
all.equal(corpus_text$text[3], 'run run'),
all.equal(corpus_text$count[3], 2),
all.equal(corpus_text$text[4], 'run shoe'),
all.equal(corpus_text$count[4], 2),
all.equal(corpus_text$text[5], 'run'),
all.equal(corpus_text$count[5], 1),
all.equal(corpus_text$text[6], 'run'),
all.equal(corpus_text$count[6], 1)
)
}
test_lemmatize_corpus()
# This function calculates the score of matches between a list of queries and
# a list of texts. We are trying different methods to calculate the score here,
# so rather than reading the method from documentation, review how it works from
# test function test_calculate_match_score (Yes, I do love TDD).
calculate_match_score <- function(queries, texts) {
scores <- list(length=length(queries))
for (i in 1:length(queries)) {
query <- queries[i]
text <- texts[i]
# Remove leading and trailing whitespaces, then split string by whitespaces.
query_nodes <- unique(strsplit(gsub("^\\s+|\\s+$", "",
gsub("\\s+", " ", query)), " ")[[1]])
text_nodes <- unique(strsplit(gsub("^\\s+|\\s+$", "",
gsub("\\s+", " ", text)), " ")[[1]])
score <- 0
for(query_node in query_nodes) {
score <- score + length(grep(query_node, text_nodes))
}
the_score <- score / length(query_nodes)
if(the_score > 1) {the_score <- 1}
scores[[i]] <- (the_score)
}
return(as.numeric(scores))
}
# Testing function calculate_match_score
test_calculate_match_score <- function() {
queries <- c("first query",
"second query ",
"third query",
" this fourth query should",
"led christma light",
"soda stream")
texts <- c(
"first one should  return 0.5",
"this one should return 0",
"this third query   should return 1 third",
"this fourth one should return 0.75",
"set  10 batteri oper multi led train christma light  clear wire",
"sodastream home soda maker kit")
scores <- calculate_match_score(queries, texts)
stopifnot(all.equal(scores[[1]], 0.5) &&
all.equal(scores[[2]], 0) &&
all.equal(scores[[3]], 1) &&
all.equal(scores[[4]], 0.75) &&
all.equal(scores[[5]], 1) &&
all.equal(scores[[6]], 1))
}
# The initial preprocess_data function. Later after we find the better variables
# rewrite this function.
preprocess_data <- function(df) {
new_df <- data.frame(id = df$id)
browser()
cat("processing queries\n")
corpus <- prepare_corpus(df, "query")
stemmed_df <- stem_corpus(corpus)
new_df$query_stemmed <- stemmed_df$text
new_df$query_stemmed_count <- stemmed_df$count
counter <<- 0
lemma_df <- lemmatize_corpus(corpus)
new_df$query_lemma <- lemma_df$text
new_df$query_lemma_count <- lemma_df$count
cat("queries processed\n")
cat("processing product_titles\n")
corpus <- prepare_corpus(df, "product_titles")
stemmed_df <- stem_corpus(corpus)
new_df$product_title_stemmed <- stemmed_df$text
new_df$product_title_stemmed_count <- stemmed_df$count
counter <<- 0
lemma_df <- lemmatize_corpus(corpus)
new_df$product_title_lemma <- lemma_df$text
new_df$product_title_lemma_count <- lemma_df$count
cat("product_titles processed\n")
cat("processing product_descriptions\n")
corpus <- prepare_corpus(df, "product_descriptions")
stemmed_df <- stem_corpus(corpus)
new_df$product_description_stemmed <- stemmed_df$text
new_df$product_description_stemmed_count <- stemmed_df$count
counter <<- 0
lemma_df <- lemmatize_corpus(corpus)
new_df$product_description_lemma <- lemma_df$text
new_df$product_description_lemma_count <- lemma_df$count
cat("product_descriptions processed\n")
#------------------------------------------------------------------------
# Score Calculation
#------------------------------------------------------------------------
cat("calculating query vs stemmed product title match score\n")
new_df$title_stemmed_match_score <- calculate_match_score(new_df$query_stemmed, new_df$product_title_stemmed)
cat("query vs stemmed product title match score calculated\n")
cat("calculating query vs stemmed product description match score\n")
new_df$description_stemmed_match_score <- calculate_match_score(new_df$query_stemmed, new_df$product_description_stemmed)
cat("query vs stemmed product description match score calculated\n")
cat("calculating query vs lemmatized product title match score\n")
new_df$title_lemma_match_score <- calculate_match_score(new_df$query_lemma, new_df$product_title_lemma)
cat("query vs lemmatized product title match score calculated\n")
cat("calculating query vs lemmatized product description match score\n")
new_df$description_lemma_match_score <- calculate_match_score(new_df$query_lemma, new_df$product_description_lemma)
cat("query vs lemmatized product description match score calculated\n")
if ('median_relevance' %in% colnames(df)) {
new_df$median_relevance <- df$median_relevance
}
if ('relevance_variance' %in% colnames(df)) {
new_df$relevance_variance <- df$relevance_variance
}
return(new_df)
}
# This code takes awhile to run.
train <- preprocess_data(train_raw)
# The initial preprocess_data function. Later after we find the better variables
# rewrite this function.
preprocess_data <- function(df) {
new_df <- data.frame(id = df$id)
cat("processing queries\n")
corpus <- prepare_corpus(df, "query")
stemmed_df <- stem_corpus(corpus)
new_df$query_stemmed <- stemmed_df$text
new_df$query_stemmed_count <- stemmed_df$count
counter <<- 0
lemma_df <- lemmatize_corpus(corpus)
new_df$query_lemma <- lemma_df$text
new_df$query_lemma_count <- lemma_df$count
cat("queries processed\n")
cat("processing product_titles\n")
corpus <- prepare_corpus(df, "product_titles")
stemmed_df <- stem_corpus(corpus)
new_df$product_title_stemmed <- stemmed_df$text
new_df$product_title_stemmed_count <- stemmed_df$count
counter <<- 0
lemma_df <- lemmatize_corpus(corpus)
new_df$product_title_lemma <- lemma_df$text
new_df$product_title_lemma_count <- lemma_df$count
cat("product_titles processed\n")
cat("processing product_descriptions\n")
corpus <- prepare_corpus(df, "product_descriptions")
stemmed_df <- stem_corpus(corpus)
new_df$product_description_stemmed <- stemmed_df$text
new_df$product_description_stemmed_count <- stemmed_df$count
counter <<- 0
lemma_df <- lemmatize_corpus(corpus)
new_df$product_description_lemma <- lemma_df$text
new_df$product_description_lemma_count <- lemma_df$count
cat("product_descriptions processed\n")
#------------------------------------------------------------------------
# Score Calculation
#------------------------------------------------------------------------
cat("calculating query vs stemmed product title match score\n")
new_df$title_stemmed_match_score <- calculate_match_score(new_df$query_stemmed, new_df$product_title_stemmed)
cat("query vs stemmed product title match score calculated\n")
cat("calculating query vs stemmed product description match score\n")
new_df$description_stemmed_match_score <- calculate_match_score(new_df$query_stemmed, new_df$product_description_stemmed)
cat("query vs stemmed product description match score calculated\n")
cat("calculating query vs lemmatized product title match score\n")
new_df$title_lemma_match_score <- calculate_match_score(new_df$query_lemma, new_df$product_title_lemma)
cat("query vs lemmatized product title match score calculated\n")
cat("calculating query vs lemmatized product description match score\n")
new_df$description_lemma_match_score <- calculate_match_score(new_df$query_lemma, new_df$product_description_lemma)
cat("query vs lemmatized product description match score calculated\n")
if ('median_relevance' %in% colnames(df)) {
new_df$median_relevance <- df$median_relevance
}
if ('relevance_variance' %in% colnames(df)) {
new_df$relevance_variance <- df$relevance_variance
}
return(new_df)
}
# This code takes awhile to run.
train <- preprocess_data(train_raw)
counter <<- 0
# This is an equivalent of function "stemDocument" when we did our stemming algorithm earlier.
lemmatizeDocument <- function(x, language = 'en') {
suppressMessages(tagged.results <- treetag(content(x), treetagger="manual", format="obj",
TT.tknz=FALSE , lang=language,
TT.options=list(path=treetagger_path, preset="en")))
# When everything is correct, following code should display the lemma for given words:
tagged_results <- tagged.results@TT.res
counter <<- counter + 1
cat("count: ", counter, "\n")
return(PlainTextDocument(paste(unlist(tagged_results$lemma),collapse=' ')))
}
lemmatize_corpus <- function(corpus) {
corpus <- tm_map(corpus, lemmatizeDocument)
# tagged.results <- treetag(corpus$content, treetagger="manual", format="obj",
#                       TT.tknz=FALSE , lang=language,
#                       TT.options=list(path=treetagger_path, preset="en"))
tagged_results <- tagged.results@TT.res
corpus_text <- data.frame(
text=unlist(sapply(corpus, `[`, "content")),
stringsAsFactors=F
)
# "Simple" word count with regex.
corpus_text$count <- sapply(gregexpr("\\b\\W+\\b", corpus_text$text, perl=TRUE), function(x) sum(x>0) ) + 1
return(corpus_text)
}
test_lemmatize_corpus <- function() {
df <- data.frame(query = c('run',
'running',
'runs running',
'running shoes',
'ran',
'I am running'))
df$query <- as.character(df$query)
corpus <- prepare_corpus(df, 'query')
# corpus_text <- lemmatizeDocument(df$query)
corpus_text <- lemmatize_corpus(corpus)
stopifnot(
all.equal(corpus_text$text[1], 'run'),
all.equal(corpus_text$count[1], 1),
all.equal(corpus_text$text[2], 'run'),
all.equal(corpus_text$count[2], 1),
all.equal(corpus_text$text[3], 'run run'),
all.equal(corpus_text$count[3], 2),
all.equal(corpus_text$text[4], 'run shoe'),
all.equal(corpus_text$count[4], 2),
all.equal(corpus_text$text[5], 'run'),
all.equal(corpus_text$count[5], 1),
all.equal(corpus_text$text[6], 'run'),
all.equal(corpus_text$count[6], 1)
)
}
test_lemmatize_corpus()
# This code takes awhile to run.
train <- preprocess_data(train_raw)
quick_lemmatizer(x) {
alltext = paste(unlist(x), collapse = " theseparator ")
browser()
}
test_quick_lemmatizer <- function() {
test_lemmatize_corpus <- function() {
df <- data.frame(query = c('run',
'running',
'runs running',
'running shoes',
'ran',
'I am running'))
df$query <- as.character(df$query)
# corpus <- prepare_corpus(df, 'query')
corpus_text <- quick_lemmatizer(df$query)
stopifnot(
all.equal(corpus_text$text[1], 'run'),
all.equal(corpus_text$count[1], 1),
all.equal(corpus_text$text[2], 'run'),
all.equal(corpus_text$count[2], 1),
all.equal(corpus_text$text[3], 'run run'),
all.equal(corpus_text$count[3], 2),
all.equal(corpus_text$text[4], 'run shoe'),
all.equal(corpus_text$count[4], 2),
all.equal(corpus_text$text[5], 'run'),
all.equal(corpus_text$count[5], 1),
all.equal(corpus_text$text[6], 'run'),
all.equal(corpus_text$count[6], 1)
)
}
quick_lemmatizer(x) {
alltext = paste(unlist(x), collapse = " theseparator ")
browser()
}
test_quick_lemmatizer <- function() {
test_lemmatize_corpus <- function() {
df <- data.frame(query = c('run',
'running',
'runs running',
'running shoes',
'ran',
'I am running'))
df$query <- as.character(df$query)
# corpus <- prepare_corpus(df, 'query')
corpus_text <- quick_lemmatizer(x = df$query)
stopifnot(
all.equal(corpus_text$text[1], 'run'),
all.equal(corpus_text$count[1], 1),
all.equal(corpus_text$text[2], 'run'),
all.equal(corpus_text$count[2], 1),
all.equal(corpus_text$text[3], 'run run'),
all.equal(corpus_text$count[3], 2),
all.equal(corpus_text$text[4], 'run shoe'),
all.equal(corpus_text$count[4], 2),
all.equal(corpus_text$text[5], 'run'),
all.equal(corpus_text$count[5], 1),
all.equal(corpus_text$text[6], 'run'),
all.equal(corpus_text$count[6], 1)
)
}
quick_lemmatizer(x) {
browser()
alltext = paste(unlist(x), collapse = " theseparator ")
browser()
}
test_quick_lemmatizer <- function() {
test_lemmatize_corpus <- function() {
df <- data.frame(query = c('run',
'running',
'runs running',
'running shoes',
'ran',
'I am running'))
df$query <- as.character(df$query)
# corpus <- prepare_corpus(df, 'query')
corpus_text <- quick_lemmatizer(x = df$query)
stopifnot(
all.equal(corpus_text$text[1], 'run'),
all.equal(corpus_text$count[1], 1),
all.equal(corpus_text$text[2], 'run'),
all.equal(corpus_text$count[2], 1),
all.equal(corpus_text$text[3], 'run run'),
all.equal(corpus_text$count[3], 2),
all.equal(corpus_text$text[4], 'run shoe'),
all.equal(corpus_text$count[4], 2),
all.equal(corpus_text$text[5], 'run'),
all.equal(corpus_text$count[5], 1),
all.equal(corpus_text$text[6], 'run'),
all.equal(corpus_text$count[6], 1)
)
}
exit
x
;lasmd;da
quick_lemmatizer(x) {
e
quick_lemmatizer(x) {
browser()
alltext = paste(unlist(x), collapse = " theseparator ")
browser()
}
test_quick_lemmatizer <- function() {
test_lemmatize_corpus <- function() {
df <- data.frame(query = c('run',
'running',
'runs running',
'running shoes',
'ran',
'I am running'))
df$query <- as.character(df$query)
# corpus <- prepare_corpus(df, 'query')
corpus_text <- quick_lemmatizer(x = df$query)
stopifnot(
all.equal(corpus_text$text[1], 'run'),
all.equal(corpus_text$count[1], 1),
all.equal(corpus_text$text[2], 'run'),
all.equal(corpus_text$count[2], 1),
all.equal(corpus_text$text[3], 'run run'),
all.equal(corpus_text$count[3], 2),
all.equal(corpus_text$text[4], 'run shoe'),
all.equal(corpus_text$count[4], 2),
all.equal(corpus_text$text[5], 'run'),
all.equal(corpus_text$count[5], 1),
all.equal(corpus_text$text[6], 'run'),
all.equal(corpus_text$count[6], 1)
)
}
asd
;ldp[wl]
dal[p]
dp[la]
[pdlwapdlw[al]]
pldlwa
